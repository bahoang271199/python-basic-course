{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Text Analysis Tool (Command-Line Tool)\n",
    "\n",
    "This project will create a command-line tool to analyze a text file. The tool will read the file's content and provide basic statistics such as total character count, total word count, total line count, and the frequency of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Initialization and Setup\n",
    "\n",
    "We'll import necessary modules (`os` to check files, `sys` to read command-line arguments) and create a sample text file for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'sample_text.txt' for testing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re # Regular expression module for cleaning words\n",
    "\n",
    "# Create a sample text file for testing\n",
    "sample_text_content = \"\"\"\n",
    "This is a sample text file for analysis.\n",
    "It contains multiple lines.\n",
    "Python is powerful, and python is fun!\n",
    "Let's analyze this text.\n",
    "\"\"\".strip()\n",
    "\n",
    "with open('sample_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text_content)\n",
    "\n",
    "print(\"Created 'sample_text.txt' for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Text File Reading Function\n",
    "\n",
    "The `read_text_file()` function will be responsible for reading the file's content. It will handle errors if the file does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(filepath):\n",
    "    \"\"\"Reads the content of a text file.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: File '{filepath}' does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{filepath}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Text Analysis Function\n",
    "\n",
    "The `analyze_text()` function will perform character, word, and line counts, and calculate word frequencies. We'll use string methods and dictionaries to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text_content):\n",
    "    \"\"\"Analyzes text content and returns statistics.\"\"\"\n",
    "    if not text_content:\n",
    "        return {\n",
    "            'char_count': 0,\n",
    "            'word_count': 0,\n",
    "            'line_count': 0,\n",
    "            'word_frequency': {}\n",
    "        }\n",
    "\n",
    "    # Count characters (including spaces and newlines)\n",
    "    char_count = len(text_content)\n",
    "\n",
    "    # Count lines\n",
    "    line_count = text_content.count('\\n') + 1 # Add 1 because the last line might not have a \\n\n",
    "\n",
    "    # Count words and word frequency\n",
    "    # Remove punctuation and convert all to lowercase\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text_content).lower() # Keep letters, numbers, underscores, spaces\n",
    "    words = cleaned_text.split()\n",
    "    word_count = len(words)\n",
    "\n",
    "    word_frequency = {}\n",
    "    for word in words:\n",
    "        if word:\n",
    "            word_frequency[word] = word_frequency.get(word, 0) + 1\n",
    "\n",
    "    return {\n",
    "        'char_count': char_count,\n",
    "        'word_count': word_count,\n",
    "        'line_count': line_count,\n",
    "        'word_frequency': word_frequency\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Display Analysis Results Function\n",
    "\n",
    "This function will print the statistics clearly and readably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_analysis_results(results):\n",
    "    \"\"\"Displays the text analysis statistics.\"\"\"\n",
    "    print(\"\\n--- TEXT ANALYSIS RESULTS ---\")\n",
    "    print(f\"Total Characters: {results['char_count']}\")\n",
    "    print(f\"Total Words: {results['word_count']}\")\n",
    "    print(f\"Total Lines: {results['line_count']}\")\n",
    "\n",
    "    print(\"\\n--- Word Frequency ---\")\n",
    "    if not results['word_frequency']:\n",
    "        print(\"No words to analyze.\")\n",
    "        return\n",
    "\n",
    "    # Sort word frequency by count in descending order\n",
    "    sorted_word_freq = sorted(results['word_frequency'].items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    for word, count in sorted_word_freq:\n",
    "        print(f\"'{word}': {count}\")\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Main Tool Logic (Using `sys.argv`)\n",
    "\n",
    "This is the main part of the script. It will check command-line arguments to get the file path, then call the defined functions to read, analyze, and display the results.\n",
    "\n",
    "**To run this section:**\n",
    "\n",
    "If you are in a Jupyter Notebook, you can simulate `sys.argv` by assigning to it manually. For example:\n",
    "\n",
    "```python\n",
    "sys.argv = ['your_script_name.py', 'sample_text.txt'] # Replace 'sample_text.txt' with your file name\n",
    "```\n",
    "\n",
    "If you run from the terminal, save this code into a `.py` file (e.g., `text_analyzer.py`) and run:\n",
    "\n",
    "```bash\n",
    "python text_analyzer.py sample_text.txt\n",
    "```\n",
    "Or with another file:\n",
    "```bash\n",
    "python text_analyzer.py path/to/your/other_file.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file: sample_text.txt\n",
      "\n",
      "--- TEXT ANALYSIS RESULTS ---\n",
      "Total Characters: 132\n",
      "Total Words: 23\n",
      "Total Lines: 4\n",
      "\n",
      "--- Word Frequency ---\n",
      "'is': 3\n",
      "'this': 2\n",
      "'text': 2\n",
      "'python': 2\n",
      "'a': 1\n",
      "'sample': 1\n",
      "'file': 1\n",
      "'for': 1\n",
      "'analysis': 1\n",
      "'it': 1\n",
      "'contains': 1\n",
      "'multiple': 1\n",
      "'lines': 1\n",
      "'powerful': 1\n",
      "'and': 1\n",
      "'fun': 1\n",
      "'lets': 1\n",
      "'analyze': 1\n",
      "------------------------------------\n",
      "\n",
      "Removed 'sample_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function controlling the text analysis tool.\"\"\"\n",
    "    # sys.argv[0] is the script name, sys.argv[1] is the first argument\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python text_analyzer.py <text_file_path>\")\n",
    "        print(\"Example: python text_analyzer.py sample_text.txt\")\n",
    "        return\n",
    "\n",
    "    filepath = sys.argv[1]\n",
    "    print(f\"Analyzing file: {filepath}\")\n",
    "\n",
    "    text_content = read_text_file(filepath)\n",
    "\n",
    "    if text_content is not None:\n",
    "        analysis_results = analyze_text(text_content)\n",
    "        display_analysis_results(analysis_results)\n",
    "\n",
    "# To run in Jupyter Notebook, you need to simulate sys.argv\n",
    "# Example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Uncomment the line below to test in Jupyter with the sample file\n",
    "    sys.argv = ['your_script_name.py', 'sample_text.txt'] \n",
    "    main()\n",
    "\n",
    "# Clean up the dummy file after execution\n",
    "if os.path.exists('sample_text.txt'):\n",
    "    os.remove('sample_text.txt')\n",
    "    print(\"\\nRemoved 'sample_text.txt'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusion\n",
    "\n",
    "You have built a simple but effective text analysis tool! This project helped you practice: file reading, string manipulation, using dictionaries for frequency counting, and interacting with command-line arguments. This is a good foundation for you to expand into more complex text analysis tools in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
